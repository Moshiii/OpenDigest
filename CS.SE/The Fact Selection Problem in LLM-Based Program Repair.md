
# Title: The Fact Selection Problem in LLM-Based Program Repair
#### 8 Apr 2024 https://arxiv.org/pdf/2404.05520.pdf

This paper discusses the importance of incorporating bug-related facts into prompts to improve bug-fixing capabilities of large language models (LLMs). 

### Key Research Problem:
The key research problem it solves is determining the optimal set of bug-related facts to include in prompts to maximize bug-fixing success. 

### Method:
The method applied involves conducting a large-scale study with over 19K prompts featuring various combinations of seven diverse facts to rectify bugs in open-source Python projects. 

### Performance:
The performance of this method is significant, with findings showing that each fact included in prompts contributes to fixing bugs that may remain unresolved otherwise. 

### Novelty:
The novelty of this work lies in the fact selection problem, where a statistical model named Maniple is developed to select specific facts for each bug, surpassing the performance of generic fact sets. 

### Potential:
The potential of this work is promising, as Maniple outperforms state-of-the-art bug repair methods, repairing 88 bugs out of 157 in the testing dataset. 

### Impact:
The impact on the market is substantial as it provides a more effective approach to bug-fixing using language models, which can enhance software development processes and reduce maintenance time and costs.



